{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "seeing-cylinder",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python\n",
    "# coding: utf-8\n",
    "from __future__ import absolute_import, division, print_function, unicode_literals\n",
    "\n",
    "import numpy as np\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "import copy\n",
    "import pickle\n",
    "import os\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import datasets, layers, models\n",
    "from tensorflow.keras.layers import Input, concatenate, Conv2D, MaxPooling2D, Conv2DTranspose, BatchNormalization, Activation\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "random.seed(42)\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"   \n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\"\n",
    "\n",
    "scale = 224\n",
    "    \n",
    "with open('Dataset_0908.pkl','rb') as r:\n",
    "    data = pickle.load(r)\n",
    "    \n",
    "with open('HMDB_BMRB_v5.pkl','rb') as r:\n",
    "    raw = pickle.load(r)    \n",
    "    \n",
    "encode = dict((c,n) for n,c in enumerate(raw))\n",
    "keys = list(data.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "verified-guide",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = np.zeros((len(data)),int)\n",
    "for n, i in tqdm(enumerate(data)):\n",
    "    labels[n] = data[i]['Target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "judicial-cleanup",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_list, val_list, _, _, = train_test_split(keys,labels,test_size=1/10,random_state=42,stratify=labels)\n",
    "train_list, test_list, _, _, = train_test_split(keys,labels,test_size=1/9,random_state=42,stratify=labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aquatic-jungle",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_unet(img_size):\n",
    "    inputs = Input(shape=img_size + (2,))\n",
    "    conv1 = Conv2D(64, (3, 3), padding='same')(inputs)\n",
    "    conv1 = BatchNormalization()(conv1)\n",
    "    conv1 = Activation('relu')(conv1)\n",
    "    conv1 = Conv2D(64, (3, 3), padding='same')(conv1)\n",
    "    conv1 = BatchNormalization()(conv1)\n",
    "    conv1 = Activation('relu')(conv1)\n",
    "    conv1 = Conv2D(64, (3, 3), padding='same')(conv1)\n",
    "    conv1 = BatchNormalization()(conv1)\n",
    "    conv1 = Activation('relu')(conv1)\n",
    "    pool1 = MaxPooling2D(pool_size=(2, 2))(conv1)\n",
    "\n",
    "    conv2 = Conv2D(128, (3, 3), padding='same')(pool1)\n",
    "    conv2 = BatchNormalization()(conv2)\n",
    "    conv2 = Activation('relu')(conv2)\n",
    "    conv2 = Conv2D(128, (3, 3), padding='same')(conv2)\n",
    "    conv2 = BatchNormalization()(conv2)\n",
    "    conv2 = Activation('relu')(conv2)\n",
    "    conv2 = Conv2D(128, (3, 3), padding='same')(conv2)\n",
    "    conv2 = BatchNormalization()(conv2)\n",
    "    conv2 = Activation('relu')(conv2)\n",
    "    pool2 = MaxPooling2D(pool_size=(2, 2))(conv2)\n",
    "    \n",
    "    conv3 = Conv2D(256, (3, 3), padding='same')(pool2)\n",
    "    conv3 = BatchNormalization()(conv3)\n",
    "    conv3 = Activation('relu')(conv3)\n",
    "    conv3 = Conv2D(256, (3, 3), padding='same')(conv3)\n",
    "    conv3 = BatchNormalization()(conv3)\n",
    "    conv3 = Activation('relu')(conv3)\n",
    "    conv3 = Conv2D(256, (3, 3), padding='same')(conv3)\n",
    "    conv3 = BatchNormalization()(conv3)\n",
    "    conv3 = Activation('relu')(conv3)\n",
    "    pool3 = MaxPooling2D(pool_size=(2, 2))(conv3)\n",
    "\n",
    "    conv4 = Conv2D(512, (3, 3), padding='same')(pool3)\n",
    "    conv4 = BatchNormalization()(conv4)\n",
    "    conv4 = Activation('relu')(conv4)\n",
    "    conv4 = Conv2D(512, (3, 3), padding='same')(conv4)\n",
    "    conv4 = BatchNormalization()(conv4)\n",
    "    conv4 = Activation('relu')(conv4)\n",
    "    conv4 = Conv2D(512, (3, 3), padding='same')(conv4)\n",
    "    conv4 = BatchNormalization()(conv4)\n",
    "    conv4 = Activation('relu')(conv4)\n",
    "    pool4 = MaxPooling2D(pool_size=(2, 2))(conv4)\n",
    "\n",
    "    conv5 = Conv2D(1024, (3, 3), padding='same')(pool4)\n",
    "    conv5 = BatchNormalization()(conv5)\n",
    "    conv5 = Activation('relu')(conv5)\n",
    "    conv5 = Conv2D(1024, (3, 3), padding='same')(conv5)\n",
    "    conv5 = BatchNormalization()(conv5)\n",
    "    conv5 = Activation('relu')(conv5)\n",
    "    conv5 = Conv2D(1024, (3, 3), padding='same')(conv5)\n",
    "    conv5 = BatchNormalization()(conv5)\n",
    "    conv5 = Activation('relu')(conv5)\n",
    "    pool5 = MaxPooling2D(pool_size=(2, 2))(conv5)\n",
    "\n",
    "    up6 = concatenate([Conv2DTranspose(512, (2, 2), strides=(2,2), padding='same')(conv5), conv4], axis=3)\n",
    "    conv6 = Conv2D(512, (3, 3), padding='same')(up6)\n",
    "    conv6 = BatchNormalization()(conv6)\n",
    "    conv6 = Activation('relu')(conv6)\n",
    "    conv6 = Conv2D(512, (3, 3), padding='same')(conv6)\n",
    "    conv6 = BatchNormalization()(conv6)\n",
    "    conv6 = Activation('relu')(conv6)\n",
    "    conv6 = Conv2D(512, (3, 3), padding='same')(conv6)\n",
    "    conv6 = BatchNormalization()(conv6)\n",
    "    conv6 = Activation('relu')(conv6)\n",
    "    \n",
    "\n",
    "    up7 = concatenate([Conv2DTranspose(256, (2, 2), strides=(2, 2), padding='same')(conv6), conv3], axis=3)\n",
    "    conv7 = Conv2D(256, (3, 3), padding='same')(up7)\n",
    "    conv7 = BatchNormalization()(conv7)\n",
    "    conv7 = Activation('relu')(conv7)\n",
    "    conv7 = Conv2D(256, (3, 3), padding='same')(conv7)\n",
    "    conv7 = BatchNormalization()(conv7)\n",
    "    conv7 = Activation('relu')(conv7)\n",
    "    conv7 = Conv2D(256, (3, 3), padding='same')(conv7)\n",
    "    conv7 = BatchNormalization()(conv7)\n",
    "    conv7 = Activation('relu')(conv7)\n",
    "    \n",
    "\n",
    "    up8 = concatenate([Conv2DTranspose(128, (2, 2), strides=(2, 2), padding='same')(conv7), conv2], axis=3)\n",
    "    conv8 = Conv2D(128, (3, 3), padding='same')(up8)\n",
    "    conv8 = BatchNormalization()(conv8)\n",
    "    conv8 = Activation('relu')(conv8)\n",
    "    conv8 = Conv2D(128, (3, 3), padding='same')(conv8)\n",
    "    conv8 = BatchNormalization()(conv8)\n",
    "    conv8 = Activation('relu')(conv8)\n",
    "    conv8 = Conv2D(128, (3, 3), padding='same')(conv8)\n",
    "    conv8 = BatchNormalization()(conv8)\n",
    "    conv8 = Activation('relu')(conv8)\n",
    "\n",
    "\n",
    "    up9 = concatenate([Conv2DTranspose(64, (2, 2), strides=(2, 2), padding='same')(conv8), conv1], axis=3)\n",
    "    conv9 = Conv2D(64, (3, 3), padding='same')(up9)\n",
    "    conv9 = BatchNormalization()(conv9)\n",
    "    conv9 = Activation('relu')(conv9)\n",
    "    conv9 = Conv2D(64, (3, 3), padding='same')(conv9)\n",
    "    conv9 = BatchNormalization()(conv9)\n",
    "    conv9 = Activation('relu')(conv9)\n",
    "    conv9 = Conv2D(64, (3, 3), padding='same')(conv9)\n",
    "    conv9 = BatchNormalization()(conv9)\n",
    "    conv9 = Activation('relu')(conv9)    \n",
    "\n",
    "    conv10 = Conv2D(2, (1, 1), activation='softmax',name='hsqc')(conv9)\n",
    "    \n",
    "    \n",
    "    gpool1 = layers.GlobalMaxPooling2D()(conv5)\n",
    "    \n",
    "    drop1 = layers.Dropout(0.2)(gpool1)\n",
    "    dense1 = layers.Dense(len(encode), activation = 'softmax',name='mb')(drop1)\n",
    "    \n",
    "    model = Model(inputs=inputs, outputs=[conv10,dense1])\n",
    "\n",
    "\n",
    "    return model\n",
    "\n",
    "img_size = (scale,scale)\n",
    "\n",
    "# Free up RAM in case the model definition cells were run multiple times\n",
    "keras.backend.clear_session()\n",
    "\n",
    "# Build model\n",
    "model = get_unet(img_size)\n",
    "model.compile(optimizer=keras.optimizers.Adam(lr=0.00001), loss={'mb':'sparse_categorical_crossentropy','hsqc':'sparse_categorical_crossentropy'},\n",
    "              metrics={'mb':(tf.keras.metrics.SparseTopKCategoricalAccuracy(k=2, name=\"top2\", dtype=None),\n",
    "                             tf.keras.metrics.SparseTopKCategoricalAccuracy(k=1, name=\"top1\", dtype=None)),\n",
    "                       'hsqc':'accuracy'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "about-modeling",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Datagenerator setup\n",
    "class DataGenerator(keras.utils.Sequence):\n",
    "    'Generates data for Keras'\n",
    "    def __init__(self, list_IDs, batch_size=32, dim=(scale,scale), n_channels=2,\n",
    "                 n_classes=len(encode), shuffle=True):\n",
    "        'Initialization'\n",
    "        self.dim = dim\n",
    "        self.batch_size = batch_size\n",
    "        self.list_IDs = list_IDs\n",
    "        self.n_channels = n_channels\n",
    "        self.n_classes = n_classes\n",
    "        self.shuffle = shuffle\n",
    "        self.on_epoch_end()\n",
    "\n",
    "    def __len__(self):\n",
    "        'Denotes the number of batches per epoch'\n",
    "        return int(np.floor(len(self.list_IDs) / self.batch_size))\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        'Generate one batch of data'\n",
    "        # Generate indexes of the batch\n",
    "        indexes = self.indexes[index*self.batch_size:(index+1)*self.batch_size]\n",
    "\n",
    "        # Find list of IDs\n",
    "        list_IDs_temp = [self.list_IDs[k] for k in indexes]\n",
    "\n",
    "        # Generate data\n",
    "        X,y1,y2 = self.__data_generation(list_IDs_temp)\n",
    "        \n",
    "        return X, [y1,y2]\n",
    "\n",
    "    def on_epoch_end(self):\n",
    "        'Updates indexes after each epoch'\n",
    "        self.indexes = np.arange(len(self.list_IDs))\n",
    "        if self.shuffle == True:\n",
    "            np.random.shuffle(self.indexes)\n",
    "\n",
    "    def __data_generation(self, list_IDs_temp):\n",
    "        'Generates data containing batch_size samples' # X : (n_samples, *dim, n_channels)\n",
    "        # Initialization\n",
    "        X = np.zeros((self.batch_size, *self.dim, 2), int)\n",
    "        y1 = np.zeros((self.batch_size, *self.dim,1), int)\n",
    "        y2 = np.zeros((self.batch_size,1), dtype=int)\n",
    "        \n",
    "        for n,i in enumerate(list_IDs_temp):\n",
    "            qc = np.zeros((scale,scale,3),int)\n",
    "            mat, label = data[i]['HSQC'],data[i]['Target']\n",
    "            for j in range(len(mat[0])):\n",
    "                qc[mat[0][j],mat[1][j],mat[2][j]] = 1\n",
    "            X[n], y1[n], y2[n] = qc[:,:,:2],qc[:,:,2:3],label\n",
    "\n",
    "\n",
    "        return X, y1, y2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "identical-selection",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Generate training and validation set generator\n",
    "params = {'dim': (scale,scale),\n",
    "          'batch_size': 16,\n",
    "          'n_classes': len(encode),\n",
    "          'n_channels': 2,\n",
    "          'shuffle': True}\n",
    "\n",
    "\n",
    "\n",
    "training_generator = DataGenerator(train_list, **params)\n",
    "validation_generator = DataGenerator(val_list, **params)\n",
    "test_generator = DataGenerator(test_list, **params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "smooth-timber",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Training model\n",
    "model.fit(training_generator,validation_data=validation_generator,\n",
    "            epochs=10,use_multiprocessing=False, verbose=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acquired-bracket",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Evaluation\n",
    "model.evaluate(test_generator)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
